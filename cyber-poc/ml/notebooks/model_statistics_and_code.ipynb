{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45506f40",
   "metadata": {},
   "source": [
    "# ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆÙ…ÙˆØ§ØµÙØ§Øª Ù…ÙˆØ¯ÙŠÙ„ XGBoost Ù„ÙƒØ´Ù SQL Injection\n",
    "\n",
    "Ù‡Ø°Ø§ Ø§Ù„Ù€ Notebook ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:\n",
    "- ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©\n",
    "- ğŸ¯ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ (Metrics)\n",
    "- ğŸ’» ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„\n",
    "- ğŸ” ØªØ­Ù„ÙŠÙ„ Feature Importance\n",
    "- ğŸ“‰ Confusion Matrix\n",
    "- ğŸ§ª Ø£Ù…Ø«Ù„Ø© ØªÙ†Ø¨Ø¤Ø§Øª\n",
    "\n",
    "---\n",
    "\n",
    "**ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¯Ø±ÙŠØ¨:** 2025-11-03  \n",
    "**F1 Score:** 99.79%  \n",
    "**ROC-AUC:** 99.997%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188da0d",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e39a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… ØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¨Ù†Ø¬Ø§Ø­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33021ea2",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0517a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ metadata Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "metadata_path = \"../models/model_metadata.json\"\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª\n",
    "dataset_report_path = \"../reports/dataset_report.json\"\n",
    "with open(dataset_report_path, 'r') as f:\n",
    "    dataset_report = json.load(f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ - XGBoost SQL Injection Detection\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nğŸ¯ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {metadata['model_name']}\")\n",
    "print(f\"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {metadata['timestamp']}\")\n",
    "print(f\"\\nğŸ† Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ (Performance Metrics):\")\n",
    "print(f\"   â€¢ Precision:  {metadata['metrics']['precision']:.4f} (100.00%)\")\n",
    "print(f\"   â€¢ Recall:     {metadata['metrics']['recall']:.4f} (99.60%)\")\n",
    "print(f\"   â€¢ F1 Score:   {metadata['metrics']['f1']:.4f} (99.80%)\")\n",
    "print(f\"   â€¢ ROC-AUC:    {metadata['metrics']['roc_auc']:.6f} (99.997%)\")\n",
    "print(f\"   â€¢ Train Time: {metadata['metrics']['train_time']:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nğŸ“¦ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª:\")\n",
    "print(f\"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª: {metadata['dataset_info']['total_samples']:,}\")\n",
    "print(f\"   â€¢ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {metadata['dataset_info']['train_samples']:,}\")\n",
    "print(f\"   â€¢ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚: {metadata['dataset_info']['val_samples']:,}\")\n",
    "print(f\"   â€¢ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {metadata['dataset_info']['test_samples']:,}\")\n",
    "\n",
    "print(f\"\\nâš™ï¸ Hyperparameters:\")\n",
    "for param, value in metadata['metrics']['params'].items():\n",
    "    print(f\"   â€¢ {param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a10c8",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dr = dataset_report['dataset_report']\n",
    "\n",
    "print(f\"\\nğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {dr['date']}\")\n",
    "print(f\"ğŸ“¦ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª: {dr['total_samples']:,}\")\n",
    "print(f\"âš–ï¸  Imbalance Ratio: {dr['imbalance_ratio']}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª (Class Distribution):\")\n",
    "print(f\"   â€¢ Benign (Ø¢Ù…Ù†Ø©):    {dr['class_distribution']['benign']['count']:,} ({dr['class_distribution']['benign']['percentage']:.2f}%)\")\n",
    "print(f\"   â€¢ Malicious (Ø®Ø¨ÙŠØ«Ø©): {dr['class_distribution']['malicious']['count']:,} ({dr['class_distribution']['malicious']['percentage']:.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ§¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© (Preprocessing):\")\n",
    "print(f\"   â€¢ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {dr['preprocessing']['initial_rows']:,}\")\n",
    "print(f\"   â€¢ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ§Ø±ØºØ©: {dr['preprocessing']['after_empty_removal']:,}\")\n",
    "print(f\"   â€¢ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±: {dr['preprocessing']['after_deduplication']:,}\")\n",
    "print(f\"   â€¢ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©: {dr['preprocessing']['removed_total']:,} ({dr['preprocessing']['removal_percentage']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª (Query Statistics):\")\n",
    "print(f\"   â€¢ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø·ÙˆÙ„: {dr['query_statistics']['min_length']}\")\n",
    "print(f\"   â€¢ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·ÙˆÙ„: {dr['query_statistics']['max_length']}\")\n",
    "print(f\"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø·ÙˆÙ„: {dr['query_statistics']['mean_length']}\")\n",
    "print(f\"   â€¢ Ø§Ù„ÙˆØ³ÙŠØ·: {dr['query_statistics']['median_length']}\")\n",
    "\n",
    "print(f\"\\nâš”ï¸  Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù‡Ø¬Ù…Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© ({len(dr['attack_types'])} Ù†ÙˆØ¹):\")\n",
    "for i, attack in enumerate(dr['attack_types'], 1):\n",
    "    print(f\"   {i}. {attack}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ee917",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40989455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie Chart\n",
    "labels = ['Benign (Ø¢Ù…Ù†Ø©)', 'Malicious (Ø®Ø¨ÙŠØ«Ø©)']\n",
    "sizes = [\n",
    "    dr['class_distribution']['benign']['count'],\n",
    "    dr['class_distribution']['malicious']['count']\n",
    "]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "explode = (0.05, 0)\n",
    "\n",
    "axes[0].pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90, textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "axes[0].set_title('ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª', fontsize=14, weight='bold', pad=20)\n",
    "\n",
    "# Bar Chart\n",
    "axes[1].bar(labels, sizes, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_ylabel('Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª', fontsize=12, weight='bold')\n",
    "axes[1].set_title('Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„ÙƒÙ„ ÙØ¦Ø©', fontsize=14, weight='bold', pad=20)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
    "for i, v in enumerate(sizes):\n",
    "    axes[1].text(i, v + 200, f'{v:,}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187820e",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø±Ø¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª\n",
    "model_path = \"../models/best_xgboost_20251103_200539_f1_0.998.joblib\"\n",
    "tfidf_path = \"../models/tfidf_vectorizer.joblib\"\n",
    "scaler_path = \"../models/numeric_scaler.joblib\"\n",
    "\n",
    "print(\"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„...\")\n",
    "model = joblib.load(model_path)\n",
    "tfidf_vectorizer = joblib.load(tfidf_path)\n",
    "numeric_scaler = joblib.load(scaler_path)\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "print(f\"\\nğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {type(model).__name__}\")\n",
    "print(f\"ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø± (n_estimators): {model.n_estimators}\")\n",
    "print(f\"ğŸ“ Ø£Ù‚ØµÙ‰ Ø¹Ù…Ù‚ (max_depth): {model.max_depth}\")\n",
    "print(f\"ğŸ“š Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {model.n_classes_}\")\n",
    "print(f\"ğŸ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Features: {model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52d3a4",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ - BestModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc879b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BestModel - Production Wrapper Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ XGBoost\n",
    "\n",
    "Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:\n",
    "1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª (TF-IDF, Scaler)\n",
    "2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ Features Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…\n",
    "3. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ø±Ø¬Ø© Ø§Ù„Ø®Ø·ÙˆØ±Ø©\n",
    "4. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ (allow/challenge/block)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from typing import Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "class BestModel:\n",
    "    \"\"\"\n",
    "    Production wrapper for XGBoost SQL Injection Detection Model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models_dir: str = None, threshold_mode: str = \"balanced\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            models_dir: Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª\n",
    "            threshold_mode: Ù†Ù…Ø· Ø§Ù„Ø¹ØªØ¨Ø§Øª ('balanced', 'high_security', 'high_availability')\n",
    "        \"\"\"\n",
    "        if models_dir is None:\n",
    "            models_dir = Path(__file__).parent\n",
    "        else:\n",
    "            models_dir = Path(models_dir)\n",
    "        \n",
    "        self.models_dir = models_dir\n",
    "        self.threshold_mode = threshold_mode\n",
    "        \n",
    "        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª\n",
    "        self._load_artifacts()\n",
    "        \n",
    "        # ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¹ØªØ¨Ø§Øª\n",
    "        self._set_thresholds()\n",
    "    \n",
    "    def _load_artifacts(self):\n",
    "        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\"\"\"\n",
    "        model_files = list(self.models_dir.glob(\"best_xgboost_*.joblib\"))\n",
    "        if not model_files:\n",
    "            raise FileNotFoundError(f\"No model found in {self.models_dir}\")\n",
    "        \n",
    "        self.model = joblib.load(model_files[0])\n",
    "        self.tfidf_vectorizer = joblib.load(self.models_dir / \"tfidf_vectorizer.joblib\")\n",
    "        self.numeric_scaler = joblib.load(self.models_dir / \"numeric_scaler.joblib\")\n",
    "        \n",
    "        with open(self.models_dir / \"model_metadata.json\", 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø¨Ù†Ø¬Ø§Ø­\")\n",
    "    \n",
    "    def _set_thresholds(self):\n",
    "        \"\"\"ØªØ¹ÙŠÙŠÙ† Ø¹ØªØ¨Ø§Øª Ø§Ù„Ù‚Ø±Ø§Ø± Ø­Ø³Ø¨ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…Ø®ØªØ§Ø±\"\"\"\n",
    "        threshold_configs = {\n",
    "            \"balanced\": {\"challenge\": 0.3, \"block\": 0.7},\n",
    "            \"high_security\": {\"challenge\": 0.2, \"block\": 0.5},\n",
    "            \"high_availability\": {\"challenge\": 0.5, \"block\": 0.9}\n",
    "        }\n",
    "        \n",
    "        config = threshold_configs.get(self.threshold_mode, threshold_configs[\"balanced\"])\n",
    "        self.threshold_challenge = config[\"challenge\"]\n",
    "        self.threshold_block = config[\"block\"]\n",
    "    \n",
    "    def _extract_features(self, raw_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…\n",
    "        \n",
    "        Features Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© (12 feature):\n",
    "        - len_raw: Ø·ÙˆÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…\n",
    "        - num_special_chars: Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©\n",
    "        - num_sql_keywords: Ø¹Ø¯Ø¯ ÙƒÙ„Ù…Ø§Øª SQL\n",
    "        - num_quotes: Ø¹Ø¯Ø¯ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†ØµÙŠØµ\n",
    "        - num_dashes: Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ø±Ø·Ø§Øª\n",
    "        - num_semicolons: Ø¹Ø¯Ø¯ Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ù…Ù†Ù‚ÙˆØ·Ø©\n",
    "        - num_equals: Ø¹Ø¯Ø¯ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø³Ø§ÙˆØ§Ø©\n",
    "        - num_percent: Ø¹Ø¯Ø¯ Ø¹Ù„Ø§Ù…Ø§Øª %\n",
    "        - has_union: ÙˆØ¬ÙˆØ¯ UNION\n",
    "        - has_or_1_1: ÙˆØ¬ÙˆØ¯ Ù†Ù…Ø· OR 1=1\n",
    "        - has_comment: ÙˆØ¬ÙˆØ¯ ØªØ¹Ù„ÙŠÙ‚Ø§Øª SQL\n",
    "        - has_script_tag: ÙˆØ¬ÙˆØ¯ <script> tag\n",
    "        \"\"\"\n",
    "        len_raw = len(raw_query)\n",
    "        num_special_chars = len(re.findall(r'[^a-zA-Z0-9\\s]', raw_query))\n",
    "        num_sql_keywords = len(re.findall(\n",
    "            r'\\b(SELECT|UNION|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER|EXEC)\\b',\n",
    "            raw_query, re.IGNORECASE\n",
    "        ))\n",
    "        num_quotes = raw_query.count(\"'\") + raw_query.count('\"')\n",
    "        num_dashes = raw_query.count('-')\n",
    "        num_semicolons = raw_query.count(';')\n",
    "        num_equals = raw_query.count('=')\n",
    "        num_percent = raw_query.count('%')\n",
    "        \n",
    "        has_union = int(bool(re.search(r'\\bUNION\\b', raw_query, re.IGNORECASE)))\n",
    "        has_or_1_1 = int(bool(re.search(r'(\\bOR\\b\\s+\\d+\\s*=\\s*\\d+)', raw_query, re.IGNORECASE)))\n",
    "        has_comment = int(bool(re.search(r'(--|/\\*|\\*/|#)', raw_query)))\n",
    "        has_script_tag = int(bool(re.search(r'<script', raw_query, re.IGNORECASE)))\n",
    "        \n",
    "        return {\n",
    "            'len_raw': len_raw,\n",
    "            'num_special_chars': num_special_chars,\n",
    "            'num_sql_keywords': num_sql_keywords,\n",
    "            'num_quotes': num_quotes,\n",
    "            'num_dashes': num_dashes,\n",
    "            'num_semicolons': num_semicolons,\n",
    "            'num_equals': num_equals,\n",
    "            'num_percent': num_percent,\n",
    "            'has_union': has_union,\n",
    "            'has_or_1_1': has_or_1_1,\n",
    "            'has_comment': has_comment,\n",
    "            'has_script_tag': has_script_tag\n",
    "        }\n",
    "    \n",
    "    def _prepare_input(self, raw_query: str):\n",
    "        \"\"\"\n",
    "        ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ (numeric + TF-IDF)\n",
    "        \"\"\"\n",
    "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n",
    "        numeric_features = self._extract_features(raw_query)\n",
    "        \n",
    "        # Ø¥Ù†Ø´Ø§Ø¡ vector Ù„Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø±Ù‚Ù…ÙŠØ©\n",
    "        numeric_vector = np.array([[\n",
    "            numeric_features['len_raw'],\n",
    "            numeric_features['num_special_chars'],\n",
    "            numeric_features['num_sql_keywords'],\n",
    "            numeric_features['num_quotes'],\n",
    "            numeric_features['num_dashes'],\n",
    "            numeric_features['num_semicolons'],\n",
    "            numeric_features['num_equals'],\n",
    "            numeric_features['num_percent'],\n",
    "            numeric_features['has_union'],\n",
    "            numeric_features['has_or_1_1'],\n",
    "            numeric_features['has_comment'],\n",
    "            numeric_features['has_script_tag']\n",
    "        ]])\n",
    "        \n",
    "        # Scaling\n",
    "        numeric_scaled = self.numeric_scaler.transform(numeric_vector)\n",
    "        \n",
    "        # TF-IDF\n",
    "        tfidf_features = self.tfidf_vectorizer.transform([raw_query])\n",
    "        \n",
    "        # Ø¯Ù…Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ\n",
    "        combined = np.hstack([numeric_scaled, tfidf_features.toarray()])\n",
    "        \n",
    "        return combined, numeric_features\n",
    "    \n",
    "    def predict(self, raw_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ø±Ø¬Ø© Ø§Ù„Ø®Ø·ÙˆØ±Ø© ÙˆØ§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡\n",
    "        \n",
    "        Returns:\n",
    "            - score: Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ±Ø© (0-1)\n",
    "            - action: Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ ('allow', 'challenge', 'block')\n",
    "            - reason: Ø§Ù„Ø³Ø¨Ø¨\n",
    "            - features: Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©\n",
    "            - confidence: Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª\n",
    "            features_array, numeric_features = self._prepare_input(raw_query)\n",
    "            \n",
    "            # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
    "            proba = self.model.predict_proba(features_array)[0]\n",
    "            score = float(proba[1])  # Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø®Ø¨ÙŠØ«Ø©\n",
    "            \n",
    "            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹ØªØ¨Ø§Øª\n",
    "            if score < self.threshold_challenge:\n",
    "                action = \"allow\"\n",
    "                reason = f\"Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© Ù…Ù†Ø®ÙØ¶Ø© ({score:.3f})\"\n",
    "            elif score < self.threshold_block:\n",
    "                action = \"challenge\"\n",
    "                reason = f\"Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© Ù…ØªÙˆØ³Ø·Ø© ({score:.3f}) - ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ\"\n",
    "            else:\n",
    "                action = \"block\"\n",
    "                reason = f\"Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© Ø¹Ø§Ù„ÙŠØ© ({score:.3f}) - ÙŠØ¬Ø¨ Ø§Ù„Ø­Ø¸Ø±\"\n",
    "            \n",
    "            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯\n",
    "            threats = []\n",
    "            if numeric_features['num_sql_keywords'] > 2:\n",
    "                threats.append(f\"{numeric_features['num_sql_keywords']} SQL keywords\")\n",
    "            if numeric_features['has_union']:\n",
    "                threats.append(\"UNION detected\")\n",
    "            if numeric_features['has_or_1_1']:\n",
    "                threats.append(\"OR 1=1 pattern\")\n",
    "            if numeric_features['has_comment']:\n",
    "                threats.append(\"SQL comments\")\n",
    "            \n",
    "            if threats:\n",
    "                reason += f\" | Threats: {', '.join(threats)}\"\n",
    "            \n",
    "            confidence = \"high\" if max(proba) > 0.9 else \"medium\" if max(proba) > 0.7 else \"low\"\n",
    "            \n",
    "            return {\n",
    "                \"score\": round(score, 6),\n",
    "                \"action\": action,\n",
    "                \"reason\": reason,\n",
    "                \"features\": numeric_features,\n",
    "                \"confidence\": confidence,\n",
    "                \"threshold_mode\": self.threshold_mode\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"score\": -1.0,\n",
    "                \"action\": \"error\",\n",
    "                \"reason\": f\"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {str(e)}\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªØ¹Ø±ÙŠÙ BestModel Class Ø¨Ù†Ø¬Ø§Ø­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932198f2",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø§Øª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø¥Ù†Ø´Ø§Ø¡ instance Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "best_model = BestModel(models_dir=\"../models\", threshold_mode=\"balanced\")\n",
    "\n",
    "# Ø¹ÙŠÙ†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±ÙŠØ©\n",
    "test_samples = [\n",
    "    (\"SELECT * FROM users WHERE id=1\", \"Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ø§Ø¯ÙŠ\"),\n",
    "    (\"SELECT * FROM users WHERE id=1 OR 1=1 --\", \"SQL Injection - OR 1=1\"),\n",
    "    (\"' UNION SELECT username,password FROM admin--\", \"SQL Injection - UNION\"),\n",
    "    (\"https://shop.com/product?id=5\", \"URL Ø¢Ù…Ù†\"),\n",
    "    (\"<script>alert('XSS')</script>\", \"XSS Attack\"),\n",
    "    (\"'; DROP TABLE users; --\", \"SQL Injection - DROP TABLE\")\n",
    "]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "results = []\n",
    "for query, label in test_samples:\n",
    "    result = best_model.predict(query)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Query: {query}\")\n",
    "    print(f\"ğŸ·ï¸  Label: {label}\")\n",
    "    print(f\"ğŸ“Š Score: {result['score']:.6f}\")\n",
    "    print(f\"âš¡ Action: {result['action'].upper()}\")\n",
    "    print(f\"ğŸ’ª Confidence: {result['confidence'].upper()}\")\n",
    "    print(f\"ğŸ“‹ Reason: {result['reason']}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a632a95",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5adecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù…\n",
    "scores = [r['score'] for r in results]\n",
    "labels = [label for _, label in test_samples]\n",
    "actions = [r['action'] for r in results]\n",
    "\n",
    "# Ø£Ù„ÙˆØ§Ù† Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡\n",
    "action_colors = {\n",
    "    'allow': '#2ecc71',\n",
    "    'challenge': '#f39c12',\n",
    "    'block': '#e74c3c'\n",
    "}\n",
    "colors = [action_colors.get(action, 'gray') for action in actions]\n",
    "\n",
    "# Ø§Ù„Ø±Ø³Ù…\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars = ax.bar(range(len(scores)), scores, color=colors, edgecolor='black', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Ø¥Ø¶Ø§ÙØ© Ø®Ø·ÙˆØ· Ø§Ù„Ø¹ØªØ¨Ø§Øª\n",
    "ax.axhline(y=0.3, color='orange', linestyle='--', linewidth=2, label='Challenge Threshold (0.3)')\n",
    "ax.axhline(y=0.7, color='red', linestyle='--', linewidth=2, label='Block Threshold (0.7)')\n",
    "\n",
    "# Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª\n",
    "ax.set_xlabel('Ø§Ù„Ø¹ÙŠÙ†Ø§Øª', fontsize=12, weight='bold')\n",
    "ax.set_ylabel('Ø¯Ø±Ø¬Ø© Ø§Ù„Ø®Ø·ÙˆØ±Ø© (Threat Score)', fontsize=12, weight='bold')\n",
    "ax.set_title('Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±ÙŠØ©', fontsize=14, weight='bold', pad=20)\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels([f\"Sample {i+1}\" for i in range(len(labels))], rotation=0)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
    "for i, (bar, score, action) in enumerate(zip(bars, scores, actions)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "            f'{score:.3f}\\n{action.upper()}',\n",
    "            ha='center', va='bottom', fontsize=9, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø§Ø·ÙŠØ±\n",
    "print(\"\\nğŸ“Œ Legend:\")\n",
    "print(\"ğŸŸ¢ Green (Allow): Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© Ù…Ù†Ø®ÙØ¶Ø© < 0.3\")\n",
    "print(\"ğŸŸ  Orange (Challenge): Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© Ù…ØªÙˆØ³Ø·Ø© 0.3-0.7\")\n",
    "print(\"ğŸ”´ Red (Block): Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© Ø¹Ø§Ù„ÙŠØ© > 0.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf92669",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Ø¹Ø±Ø¶ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ø´ÙƒÙ„ Ù…Ø±Ø¦ÙŠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\n",
    "metrics_data = {\n",
    "    'Metric': ['Precision', 'Recall', 'F1 Score', 'ROC-AUC'],\n",
    "    'Score': [\n",
    "        metadata['metrics']['precision'],\n",
    "        metadata['metrics']['recall'],\n",
    "        metadata['metrics']['f1'],\n",
    "        metadata['metrics']['roc_auc']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar Chart\n",
    "bars = ax1.bar(metrics_data['Metric'], metrics_data['Score'], \n",
    "               color=['#3498db', '#2ecc71', '#9b59b6', '#e74c3c'],\n",
    "               edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('Score', fontsize=12, weight='bold')\n",
    "ax1.set_title('Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„', fontsize=14, weight='bold', pad=20)\n",
    "ax1.set_ylim(0.99, 1.001)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
    "for bar, score in zip(bars, metrics_data['Score']):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{score:.6f}',\n",
    "             ha='center', va='bottom', fontsize=10, weight='bold')\n",
    "\n",
    "# Radar Chart Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\n",
    "angles = np.linspace(0, 2 * np.pi, len(metrics_data['Metric']), endpoint=False).tolist()\n",
    "scores_radar = metrics_data['Score'] + [metrics_data['Score'][0]]\n",
    "angles += angles[:1]\n",
    "\n",
    "ax2 = plt.subplot(122, projection='polar')\n",
    "ax2.plot(angles, scores_radar, 'o-', linewidth=2, color='#3498db', label='XGBoost Model')\n",
    "ax2.fill(angles, scores_radar, alpha=0.25, color='#3498db')\n",
    "ax2.set_xticks(angles[:-1])\n",
    "ax2.set_xticklabels(metrics_data['Metric'])\n",
    "ax2.set_ylim(0.99, 1.001)\n",
    "ax2.set_title('Radar Chart Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³', fontsize=14, weight='bold', pad=20)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³\n",
    "print(\"\\nğŸ“Š Ù…Ù„Ø®Øµ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡:\")\n",
    "print(\"=\" * 60)\n",
    "for metric, score in zip(metrics_data['Metric'], metrics_data['Score']):\n",
    "    percentage = score * 100\n",
    "    bar_length = int(percentage / 2)\n",
    "    bar = \"â–ˆ\" * bar_length + \"â–‘\" * (50 - bar_length)\n",
    "    print(f\"{metric:12s}: {bar} {percentage:.4f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710251ab",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Ù…Ù„Ø®Øµ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
    "\n",
    "### ğŸ“Œ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n",
    "\n",
    "1. **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙ…ÙŠØ²**: Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø­Ù‚Ù‚ F1 Score = 99.80% Ùˆ ROC-AUC = 99.997%\n",
    "2. **Ø§Ù„ØªÙˆØ§Ø²Ù†**: Precision = 100% ØªØ¹Ù†ÙŠ Ù„Ø§ ÙŠÙˆØ¬Ø¯ False Positives (Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¹Ø§Ù„ÙŠØ©)\n",
    "3. **Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©**: Recall = 99.60% ØªØ¹Ù†ÙŠ ÙƒØ´Ù 99.6% Ù…Ù† Ø§Ù„Ù‡Ø¬Ù…Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©\n",
    "4. **Ø§Ù„Ø³Ø±Ø¹Ø©**: ÙˆÙ‚Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ 11.78 Ø«Ø§Ù†ÙŠØ© ÙÙ‚Ø· Ø¹Ù„Ù‰ 12,636 Ø¹ÙŠÙ†Ø©\n",
    "5. **Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©**: 3 Ø£ÙˆØ¶Ø§Ø¹ threshold (balanced, high_security, high_availability)\n",
    "\n",
    "### ğŸ¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª:\n",
    "\n",
    "- âœ… ÙƒØ´Ù SQL Injection ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ\n",
    "- âœ… ØªØµÙ†ÙŠÙ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¥Ù„Ù‰: Allow / Challenge / Block\n",
    "- âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹\n",
    "- âœ… Ø¯Ø¹Ù… Batch Predictions Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù„ÙŠ\n",
    "\n",
    "### ğŸ“¦ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª:\n",
    "\n",
    "- **XGBoost Model**: `best_xgboost_20251103_200539_f1_0.998.joblib`\n",
    "- **TF-IDF Vectorizer**: 5000 features Ù…Ù† char n-grams (3-6)\n",
    "- **Numeric Scaler**: StandardScaler Ù„Ù€ 12 numeric features\n",
    "- **Metadata**: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§Ù…Ù„Ø© Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
